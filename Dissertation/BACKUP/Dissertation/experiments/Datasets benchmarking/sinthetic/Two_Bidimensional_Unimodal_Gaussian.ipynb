{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-422ffc6c9182>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotFunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtimeit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefault_timer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'source'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(os.getcwd()).resolve().parents[2])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from source import plotFunctions\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import setup\n",
    "from source import metrics\n",
    "from methods import sliding_svm\n",
    "from methods import sliding_knn\n",
    "from methods import sliding_random_forest\n",
    "from methods import static_rf\n",
    "from methods import proposed_gmm_core_extraction\n",
    "from methods import improved_intersection\n",
    "from methods import compose\n",
    "from methods import compose_gmm_version\n",
    "from methods import fast_compose\n",
    "from methods import intersection\n",
    "from methods import testing\n",
    "\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, method, densityFunction='gmm'):\n",
    "        #commom for all experiments\n",
    "        self.method = method\n",
    "        #self.initialLabeledDataPerc=0.05 #150 instances for keystroke database and 0.05 % for artificial databases\n",
    "        #self.classes=[0, 1]\n",
    "        self.usePCA=False\n",
    "        #used only by gmm / kde process\n",
    "        self.densityFunction=densityFunction\n",
    "        self.excludingPercentage = 0.75\n",
    "        self.K_variation = 3\n",
    "        self.classifier='cluster_and_label'\n",
    "        #used in alpha-shape version only\n",
    "        self.CP=0.65\n",
    "        self.alpha=0.5\n",
    "        #used in kmeans_svm and compose only\n",
    "        self.useSVM=False\n",
    "        self.isImbalanced=False\n",
    "\n",
    "\n",
    "def doExperiments(dataValues, dataLabels, datasetDescription, arrAccSCARGC, finalAccSCARGC, experiments, numberOfTimes, batches, labeledData):\n",
    "    listOfAccuracies = []\n",
    "    listOfMethods = []\n",
    "    sizeOfBatch = int((len(dataLabels)-labeledData)/batches)#int(len(dataLabels)/batches)\n",
    "    \n",
    "    print(datasetDescription)\n",
    "    print(\"{} batches of {} instances\".format(batches, sizeOfBatch))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    for name, e in experiments.items():\n",
    "        CoreX = []\n",
    "        CoreY = []\n",
    "        elapsedTime = []\n",
    "        accTotal = []\n",
    "        accuracies=[]\n",
    "        classes = list(set(dataLabels))#getting all possible classes existent in data\n",
    "        e.sizeOfBatch = sizeOfBatch\n",
    "        e.batches = batches\n",
    "        e.dataLabels = dataLabels\n",
    "        e.dataValues = dataValues\n",
    "        e.clfName = 'knn' #rf = random forests, cl = cluster and label, knn = k-nn, svm = svm\n",
    "\n",
    "        for i in range(numberOfTimes):\n",
    "            start = timer()\n",
    "            #accuracy per step\n",
    "            algorithmName, accuracies, CoreX, CoreY = e.method.start(dataValues=e.dataValues, dataLabels=e.dataLabels, usePCA=e.usePCA, classes=classes, classifier=e.classifier, densityFunction=e.densityFunction, batches=e.batches, sizeOfBatch = e.sizeOfBatch, initialLabeledData=labeledData, excludingPercentage=e.excludingPercentage, K_variation=e.K_variation, CP=e.CP, alpha=e.alpha, clfName=e.clfName , useSVM=e.useSVM, isImbalanced=e.isImbalanced)\n",
    "            end = timer()\n",
    "            averageAccuracy = np.mean(accuracies)\n",
    "\n",
    "            #elapsed time per step\n",
    "            elapsedTime.append(end - start)\n",
    "            \n",
    "            accTotal.append(averageAccuracy)\n",
    "        \n",
    "        listOfAccuracies.append(accuracies)\n",
    "        listOfMethods.append(algorithmName)\n",
    "        #print(\"Total of \", numberOfTimes, \" experiment iterations with an average accuracy of \", np.mean(accTotal))\n",
    "        print(\"Average execution time: \", np.mean(elapsedTime))\n",
    "        metrics.finalEvaluation(accuracies, batches)\n",
    "    \n",
    "        #print data distribution in step t\n",
    "        initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "        final = initial + sizeOfBatch\n",
    "        plotFunctions.plot(dataValues[initial:final], dataLabels[initial:final], CoreX, CoreY, batches)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    print(\"SCARGC\")\n",
    "    metrics.finalEvaluation(arrAccSCARGC, batches)\n",
    "    listOfAccuracies.append(arrAccSCARGC)\n",
    "    listOfMethods.append(\"SCARGC\")\n",
    "    \n",
    "    plotFunctions.plotBoxplot(listOfAccuracies, listOfMethods)\n",
    "    \n",
    "        \n",
    "def accSCARGC(path, sep, key, steps):\n",
    "    steps = 100\n",
    "    resultsSCARGC_1, resultsSCARGC_2 = setup.loadSCARGCBoxplotResults(path, sep)\n",
    "    res = resultsSCARGC_1[key]\n",
    "    res = [ res[i::steps] for i in range(steps) ]\n",
    "    arrAcc = []\n",
    "    for i in range(steps):\n",
    "        arrAcc.append(sum(res[i])/len(res[i])*100)\n",
    "        #print(r[i])\n",
    "    #print(sum(r)/steps)\n",
    "    finalAcc = sum(arrAcc)/steps\n",
    "    return arrAcc, finalAcc\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    experiments = {}\n",
    "    is_windows = sys.platform.startswith('win')\n",
    "    sep = '\\\\'\n",
    "\n",
    "    if is_windows == False:\n",
    "        sep = '/'\n",
    "\n",
    "    path = os.getcwd()+sep+'data'+sep\n",
    "    \n",
    "    steps = 100\n",
    "    arrAccSCARGC, finalAccSCARGC = accSCARGC(path, sep, 'UG_2C_2D', steps)\n",
    "    \n",
    "    #sinthetic\n",
    "    dataValues, dataLabels, description = setup.loadUG_2C_2D(path, sep)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Paper: Core  Support  Extraction  for  Learning  from  Initially  Labeled Nonstationary  Environments  using  COMPOSE\n",
    "    link: http://s3.amazonaws.com/academia.edu.documents/45784667/2014_-_Core_Support_Extraction_for_Learning_from_Initially_Labeled_NSE_using_COMPOSE_-_IJCNN.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1489296600&Signature=9Z5DQZeDxcCtHUw7445uELSkgBg%3D&response-content-disposition=inline%3B%20filename%3DCore_support_extraction_for_learning_fro.pdf\n",
    "    '''\n",
    "    #experiments[0] = Experiment(compose_gmm_version)\n",
    "\n",
    "    '''\n",
    "    Original compose (alpha-shape version)\n",
    "    '''\n",
    "    #experiments[1] = Experiment(compose)\n",
    "\n",
    "    '''\n",
    "    SVM / Random Forest\n",
    "    '''\n",
    "    #experiments[2] = Experiment(static_svm)\n",
    "    experiments[3] = Experiment(sliding_knn)\n",
    "\n",
    "    ''' Proposed Method 1 (density function core extraction) '''\n",
    "    experiments[2] = Experiment(proposed_gmm_core_extraction, \"gmm\")\n",
    "    #experiments[4] = Experiment(proposed_gmm_core_extraction, \"kde\")\n",
    "\n",
    "    '''\n",
    "    Proposed method 2 (Intersection between two distributions with Batacharrya distance + density function)\n",
    "    '''\n",
    "    #experiments[5] = Experiment(intersection, \"gmm\")\n",
    "    #experiments[6] = Experiment(intersection, \"kde\")\n",
    "    \n",
    "    '''\n",
    "    Proposed method 3 (GMM All instances)\n",
    "    '''\n",
    "    #experiments[6] = Experiment(testing)\n",
    "\n",
    "    #params: X, y, method, num of experiment repetitions, num of batches\n",
    "    doExperiments(dataValues, dataLabels, description, arrAccSCARGC, finalAccSCARGC, experiments, 1, steps, 50)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
