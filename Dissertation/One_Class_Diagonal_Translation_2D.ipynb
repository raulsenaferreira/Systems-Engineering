{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial One Class Diagonal Translation. 2 Dimensional data.\n",
      "80 batches of 200 instances\n",
      "\n",
      "\n",
      "\n",
      "METHOD: Cluster and label as classifier and GMM with BIC and Mahalanobis as core support extraction\n",
      "Best number of components:  5\n",
      "Best number of components:  3\n",
      "Best number of components:  2\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  5\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  10\n",
      "Best number of components:  20\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  20\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  10\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  15\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  5\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  20\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  3\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  1\n",
      "Best number of components:  10\n",
      "Best number of components:  2\n",
      "Best number of components:  2\n",
      "Best number of components:  20\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n",
      "Best number of components:  2\n",
      "Best number of components:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-568111dd5476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-568111dd5476>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;31m#params: X, y, method, num of experiment repetitions, num of batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[0mdoExperiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-568111dd5476>\u001b[0m in \u001b[0;36mdoExperiments\u001b[1;34m(dataValues, dataLabels, datasetDescription, experiments, numberOfTimes, batches)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;31m#accuracy per step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0maccuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCoreX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCoreY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataLabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musePCA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musePCA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensityFunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensityFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizeOfBatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizeOfBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialLabeledDataPerc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialLabeledDataPerc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcludingPercentage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcludingPercentage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_variation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK_variation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclfName\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0museSVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0museSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misImbalanced\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misImbalanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0maverageAccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from source import plotFunctions\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import setup\n",
    "from source import metrics\n",
    "from methods import sliding_svm\n",
    "from methods import static_svm\n",
    "from methods import sliding_random_forest\n",
    "from methods import static_rf\n",
    "from methods import proposed_gmm_core_extraction\n",
    "from methods import improved_intersection\n",
    "from methods import compose\n",
    "from methods import compose_gmm_version\n",
    "'''\n",
    "from experiments.methods import compose3\n",
    "from experiments.methods import intersection\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, method):\n",
    "        #commom for all experiments\n",
    "        self.method = method\n",
    "        self.initialLabeledDataPerc=0.05\n",
    "        #self.classes=[0, 1]\n",
    "        self.usePCA=False\n",
    "        #used only by gmm and cluster-label process\n",
    "        self.densityFunction='gmm'\n",
    "        self.excludingPercentage = 0.95\n",
    "        self.K_variation = 5\n",
    "        self.classifier='cluster_and_label'\n",
    "        #used in alpha-shape version only\n",
    "        self.CP=0.65\n",
    "        self.alpha=0.5\n",
    "        #used in kmeans_svm and compose only\n",
    "        self.useSVM=False\n",
    "        self.isImbalanced=False\n",
    "\n",
    "\n",
    "def plotBoxplot(data):\n",
    "    print(\"All methods\")\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(122)\n",
    "    plt.boxplot(data)\n",
    "\n",
    "\n",
    "def doExperiments(dataValues, dataLabels, datasetDescription, experiments, numberOfTimes, batches):\n",
    "    listOfAccuracies = []\n",
    "    sizeOfBatch = int(len(dataLabels)/batches)\n",
    "    \n",
    "    print(datasetDescription)\n",
    "    print(\"{} batches of {} instances\".format(batches, sizeOfBatch))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    for name, e in experiments.items():\n",
    "        CoreX = []\n",
    "        CoreY = []\n",
    "        elapsedTime = []\n",
    "        accTotal = []\n",
    "        accuracies=[]\n",
    "        classes = list(set(dataLabels))#getting all possible classes existent in data\n",
    "        e.sizeOfBatch = sizeOfBatch\n",
    "        e.batches = batches\n",
    "        e.dataLabels = dataLabels\n",
    "        e.dataValues = dataValues\n",
    "        e.clfName = 'rf'\n",
    "\n",
    "        for i in range(numberOfTimes):\n",
    "            start = timer()\n",
    "            #accuracy per step\n",
    "            accuracies, CoreX, CoreY = e.method.start(dataValues=e.dataValues, dataLabels=e.dataLabels, usePCA=e.usePCA, classes=classes, classifier=e.classifier, densityFunction=e.densityFunction, batches=e.batches, sizeOfBatch = e.sizeOfBatch, initialLabeledDataPerc=e.initialLabeledDataPerc, excludingPercentage=e.excludingPercentage, K_variation=e.K_variation, CP=e.CP, alpha=e.alpha, clfName=e.clfName , useSVM=e.useSVM, isImbalanced=e.isImbalanced)\n",
    "            end = timer()\n",
    "            averageAccuracy = np.mean(accuracies)\n",
    "\n",
    "            #elapsed time per step\n",
    "            elapsedTime.append(end - start)\n",
    "            \n",
    "            accTotal.append(averageAccuracy)\n",
    "        \n",
    "        listOfAccuracies.append(accuracies)\n",
    "        #print(\"Total of \", numberOfTimes, \" experiment iterations with an average accuracy of \", np.mean(accTotal))\n",
    "        print(\"Average execution time: \", np.mean(elapsedTime))\n",
    "        metrics.finalEvaluation(accuracies, batches)\n",
    "        #print data distribution in step t\n",
    "        initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "        final = initial + sizeOfBatch\n",
    "        plotFunctions.plot(dataValues[initial:final], dataLabels[initial:final], CoreX, CoreY, batches)\n",
    "        print(\"\\n\\n\")\n",
    "    #plotFunctions.plotBoxplot(listOfAccuracies)\n",
    "    plotBoxplot(listOfAccuracies)\n",
    "\n",
    "\n",
    "def main():\n",
    "    experiments = {}\n",
    "    is_windows = sys.platform.startswith('win')\n",
    "    sep = '\\\\'\n",
    "\n",
    "    if is_windows == False:\n",
    "        sep = '/'\n",
    "\n",
    "    path = os.getcwd()+sep+'data'+sep\n",
    "    #sinthetic\n",
    "    dataValues, dataLabels, description = setup.loadCDT(path, sep)\n",
    "\n",
    "    '''\n",
    "    Paper: Core  Support  Extraction  for  Learning  from  Initially  Labeled Nonstationary  Environments  using  COMPOSE\n",
    "    link: http://s3.amazonaws.com/academia.edu.documents/45784667/2014_-_Core_Support_Extraction_for_Learning_from_Initially_Labeled_NSE_using_COMPOSE_-_IJCNN.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1489296600&Signature=9Z5DQZeDxcCtHUw7445uELSkgBg%3D&response-content-disposition=inline%3B%20filename%3DCore_support_extraction_for_learning_fro.pdf\n",
    "    '''\n",
    "    experiments[0] = Experiment(compose_gmm_version)\n",
    "\n",
    "    '''\n",
    "    Original compose (alpha-shape version)\n",
    "    '''\n",
    "    experiments[1] = Experiment(compose)\n",
    "\n",
    "    '''\n",
    "    SVM / Random Forest\n",
    "    '''\n",
    "    experiments[2] = Experiment(static_svm)\n",
    "    experiments[3] = Experiment(static_rf)\n",
    "\n",
    "    ''' Proposed Method 1 (GMM core extraction) '''\n",
    "    experiments[4] = Experiment(proposed_gmm_core_extraction)\n",
    "\n",
    "    ''' Proposed Method 2 (Alvim) '''\n",
    "    ##experiments[4] = Experiment(compose3, dataValues, dataLabels, \"STARTING TEST with Cluster and label as classifier and GMM / KDE as cutting data\")\n",
    "\n",
    "    '''\n",
    "    Proposed method 3 (Intersection between two distributions)\n",
    "    '''\n",
    "    ##experiments[5] = Experiment(intersection, dataValues, dataLabels, \"STARTING TEST Cluster and label as classifier and Intersection between two distributions\")\n",
    "\n",
    "    '''\n",
    "    Proposed method 4 (Intersection between two distributions + GMM)\n",
    "    '''\n",
    "    #experiments[6] = Experiment(improved_intersection)\n",
    "\n",
    "    #params: X, y, method, num of experiment repetitions, num of batches\n",
    "    doExperiments(dataValues, dataLabels, description, experiments, 1, 80)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
