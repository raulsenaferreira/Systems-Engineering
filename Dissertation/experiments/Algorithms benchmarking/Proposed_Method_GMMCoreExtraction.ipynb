{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from SCARGC algorithm (for boxplot and accuracy timelime).\n",
      "1CDT: class 0 -> 8000 instances.\n",
      "1CDT: class 1 -> 8000 instances.\n",
      "1CHT: class 0 -> 8000 instances.\n",
      "1CHT: class 1 -> 8000 instances.\n",
      "2CDT: class 0 -> 8000 instances.\n",
      "2CDT: class 1 -> 8000 instances.\n",
      "2CHT: class 0 -> 8000 instances.\n",
      "2CHT: class 1 -> 8000 instances.\n",
      "4CR: class 0 -> 36100 instances.\n",
      "4CR: class 1 -> 36100 instances.\n",
      "4CR: class 2 -> 36100 instances.\n",
      "4CR: class 3 -> 36100 instances.\n",
      "4CRE-V1: class 0 -> 31250 instances.\n",
      "4CRE-V1: class 1 -> 31250 instances.\n",
      "4CRE-V1: class 2 -> 31250 instances.\n",
      "4CRE-V1: class 3 -> 31250 instances.\n",
      "4CRE-V2: class 0 -> 45750 instances.\n",
      "4CRE-V2: class 1 -> 45750 instances.\n",
      "4CRE-V2: class 2 -> 45750 instances.\n",
      "4CRE-V2: class 3 -> 45750 instances.\n",
      "5CVT: class 0 -> 8000 instances.\n",
      "5CVT: class 1 -> 4000 instances.\n",
      "5CVT: class 2 -> 4000 instances.\n",
      "5CVT: class 3 -> 4000 instances.\n",
      "5CVT: class 4 -> 4000 instances.\n",
      "1CSurr: class 0 -> 20200 instances.\n",
      "1CSurr: class 1 -> 35083 instances.\n",
      "4CE1CF: class 0 -> 34650 instances.\n",
      "4CE1CF: class 1 -> 34650 instances.\n",
      "4CE1CF: class 2 -> 34650 instances.\n",
      "4CE1CF: class 3 -> 34650 instances.\n",
      "4CE1CF: class 4 -> 34650 instances.\n",
      "UG_2C_2D: class 0 -> 50000 instances.\n",
      "UG_2C_2D: class 1 -> 50000 instances.\n",
      "MG_2C_2D: class 0 -> 100000 instances.\n",
      "MG_2C_2D: class 1 -> 100000 instances.\n",
      "FG_2C_2D: class 0 -> 150000 instances.\n",
      "FG_2C_2D: class 1 -> 50000 instances.\n",
      "UG_2C_3D: class 0 -> 100000 instances.\n",
      "UG_2C_3D: class 1 -> 100000 instances.\n",
      "UG_2C_5D: class 0 -> 100000 instances.\n",
      "UG_2C_5D: class 1 -> 100000 instances.\n",
      "GEARS_2C_2D: class 0 -> 100000 instances.\n",
      "GEARS_2C_2D: class 1 -> 100000 instances.\n",
      "checkerboard: class 0 -> 99694 instances.\n",
      "checkerboard: class 1 -> 100306 instances.\n",
      "keystroke: class 0 -> 400 instances.\n",
      "keystroke: class 1 -> 400 instances.\n",
      "keystroke: class 2 -> 400 instances.\n",
      "keystroke: class 3 -> 400 instances.\n",
      "NOAA: class 0 -> 12461 instances.\n",
      "NOAA: class 1 -> 5698 instances.\n",
      "elecdata: class 0 -> 16106 instances.\n",
      "elecdata: class 1 -> 11446 instances.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(os.getcwd()).resolve().parents[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from source import plotFunctions\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import setup\n",
    "from source import metrics\n",
    "from methods import proposed_gmm_core_extraction\n",
    "from methods import static_knn\n",
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, method):\n",
    "        #commom for all experiments\n",
    "        self.method = method\n",
    "        #self.initialLabeledDataPerc=0.05 #150 instances for keystroke database and 0.05 % for artificial databases\n",
    "        #self.classes=[0, 1]\n",
    "        self.usePCA=False\n",
    "        #used only by gmm / kde process\n",
    "        self.densityFunction='gmm'\n",
    "        self.excludingPercentage = 0.9\n",
    "        self.K_variation = 12\n",
    "        self.classifier='cluster_and_label'\n",
    "        #used in alpha-shape version only\n",
    "        self.CP=0.65\n",
    "        self.alpha=0.5\n",
    "        #used in kmeans_svm and compose only\n",
    "        self.useSVM=False\n",
    "        self.isImbalanced=False\n",
    "\n",
    "\n",
    "def doExperiments(dataValues, dataLabels, datasetDescription, arrAccSCARGC, finalAccSCARGC, experiments, numberOfTimes, batches, labeledData):\n",
    "    listOfAccuracies = []\n",
    "    listOfMethods = []\n",
    "    sizeOfBatch = int((len(dataLabels)-labeledData)/batches)#int(len(dataLabels)/batches)\n",
    "    \n",
    "    print(datasetDescription)\n",
    "    print(\"{} batches of {} instances\".format(batches, sizeOfBatch))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    for name, e in experiments.items():\n",
    "        CoreX = []\n",
    "        CoreY = []\n",
    "        elapsedTime = []\n",
    "        accTotal = []\n",
    "        accuracies=[]\n",
    "        classes = list(set(dataLabels))#getting all possible classes existent in data\n",
    "        e.sizeOfBatch = sizeOfBatch\n",
    "        e.batches = batches\n",
    "        e.dataLabels = dataLabels\n",
    "        e.dataValues = dataValues\n",
    "        e.clfName = 'knn' #rf = random forests, cl = cluster and label, knn = k-nn, svm = svm\n",
    "\n",
    "        for i in range(numberOfTimes):\n",
    "            start = timer()\n",
    "            #accuracy per step\n",
    "            algorithmName, accuracies, CoreX, CoreY = e.method.start(dataValues=e.dataValues, dataLabels=e.dataLabels, usePCA=e.usePCA, classes=classes, classifier=e.classifier, densityFunction=e.densityFunction, batches=e.batches, sizeOfBatch = e.sizeOfBatch, initialLabeledData=labeledData, excludingPercentage=e.excludingPercentage, K_variation=e.K_variation, CP=e.CP, alpha=e.alpha, clfName=e.clfName , useSVM=e.useSVM, isImbalanced=e.isImbalanced)\n",
    "            end = timer()\n",
    "            averageAccuracy = np.mean(accuracies)\n",
    "\n",
    "            #elapsed time per step\n",
    "            elapsedTime.append(end - start)\n",
    "            \n",
    "            accTotal.append(averageAccuracy)\n",
    "        \n",
    "        listOfAccuracies.append(accuracies)\n",
    "        listOfMethods.append(algorithmName)\n",
    "        #print(\"Total of \", numberOfTimes, \" experiment iterations with an average accuracy of \", np.mean(accTotal))\n",
    "        print(\"Average execution time: \", np.mean(elapsedTime))\n",
    "        metrics.finalEvaluation(accuracies, batches)\n",
    "    \n",
    "        #print data distribution in step t\n",
    "        initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "        final = initial + sizeOfBatch\n",
    "        plotFunctions.plot(dataValues[initial:final], dataLabels[initial:final], CoreX, CoreY, batches)\n",
    "        print(\"\\n\\n\")\n",
    "    print(\"SCARGC accuracy: \",finalAccSCARGC)\n",
    "    listOfAccuracies.append(arrAccSCARGC)\n",
    "    listOfMethods.append(\"SCARGC\")\n",
    "    \n",
    "    plotFunctions.plotBoxplot(listOfAccuracies, listOfMethods)\n",
    "    \n",
    "        \n",
    "def accSCARGC(path, sep, key, steps):\n",
    "    steps = 100\n",
    "    resultsSCARGC_1, resultsSCARGC_2 = setup.loadSCARGCBoxplotResults(path, sep)\n",
    "    res = resultsSCARGC_1[key]\n",
    "    res = [ res[i::steps] for i in range(steps) ]\n",
    "    arrAcc = []\n",
    "    for i in range(steps):\n",
    "        arrAcc.append(sum(res[i])/len(res[i])*100)\n",
    "        #print(r[i])\n",
    "    #print(sum(r)/steps)\n",
    "    finalAcc = sum(arrAcc)/steps\n",
    "    return arrAcc, finalAcc\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    experiments = {}\n",
    "    is_windows = sys.platform.startswith('win')\n",
    "    sep = '\\\\'\n",
    "\n",
    "    if is_windows == False:\n",
    "        sep = '/'\n",
    "\n",
    "    path = os.getcwd()+sep+'data'+sep\n",
    "    \n",
    "    steps = 100\n",
    "    arrAccSCARGC, finalAccSCARGC = accSCARGC(path, sep, '2CDT', steps)\n",
    "    \n",
    "    #sinthetic\n",
    "    dataValues, dataLabels, description = setup.loadCDT(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadCHT(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load2CDT(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load2CHT(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load4CR(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load4CRE_V1(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load4CRE_V2(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load5CVT(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadCSurr(path, sep)\n",
    "    dataValues, dataLabels, description = setup.load4CE1CF(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadUG_2C_2D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadMG_2C_2D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadFG_2C_2D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadUG_2C_3D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadUG_2C_5D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadGEARS_2C_2D(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadCheckerBoard(path, sep)\n",
    "    #real\n",
    "    dataValues, dataLabels, description = setup.loadKeystroke(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadNOAADataset(path, sep)\n",
    "    dataValues, dataLabels, description = setup.loadElecData(path, sep)\n",
    "    \n",
    "    ''' Proposed Method 1 (GMM extracting core supports) '''\n",
    "    experiments[2] = Experiment(proposed_gmm_core_extraction)\n",
    "    \n",
    "    #experiments[1] = Experiment(sliding_svm)\n",
    "    \n",
    "    \n",
    "    #running pywidget\n",
    "    '''\n",
    "    def run(batches):\n",
    "        doExperiments(dataValues, dataLabels, description, experiments, 1, batches, 6250)\n",
    "        \n",
    "    v = interact(run, batches=(1, 100, 1)); #8 batches for keystroke and 100 batches for artificial datasets\n",
    "    display(v)\n",
    "    '''\n",
    "    #params: X, y, method, num of experiment repetitions, num of batches, num of labeled data\n",
    "    #doExperiments(dataValues, dataLabels, description, arrAccSCARGC, finalAccSCARGC, experiments, 1, steps, 50)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "2adeb28c9cd6479fb2f1046b0c0d8d02": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
