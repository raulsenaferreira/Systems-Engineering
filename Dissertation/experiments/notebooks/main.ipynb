{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6644c93e9b2e474eb428210a254152db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.main.<locals>.run>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from source import plotFunctions\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import setup\n",
    "from source import metrics\n",
    "from experiments.methods import proposed_gmm_core_extraction\n",
    "from experiments.methods import improved_intersection\n",
    "from experiments.methods import svm\n",
    "from experiments.methods import compose3\n",
    "from experiments.methods import gmm_test\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, method):\n",
    "        #commom for all experiments\n",
    "        self.method = method\n",
    "        self.initialLabeledDataPerc=0.05\n",
    "        #self.classes=[0, 1]\n",
    "        self.usePCA=False\n",
    "        #used only by gmm and cluster-label process\n",
    "        self.densityFunction='gmm'\n",
    "        self.excludingPercentage = 0.95\n",
    "        self.K = 5\n",
    "        self.classifier='cluster_and_label'\n",
    "        #used in alpha-shape version only\n",
    "        self.CP=0.65\n",
    "        self.alpha=0.5\n",
    "        #used in kmeans_svm and composeonly\n",
    "        self.useSVM=False\n",
    "        self.isImbalanced=False\n",
    "\n",
    "\n",
    "def doExperiments(dataValues, dataLabels, experiments, numberOfTimes, batches):\n",
    "    sizeOfBatch = 200 #int(len(dataLabels)/batches)\n",
    "    \n",
    "    for name, e in experiments.items():\n",
    "        CoreX = []\n",
    "        CoreY = []\n",
    "        elapsedTime = []\n",
    "        accTotal = []\n",
    "        accuracies=[]\n",
    "        classes = list(set(dataLabels))#getting all possible classes existent in data\n",
    "        e.sizeOfBatch = sizeOfBatch\n",
    "        e.batches = batches\n",
    "        e.dataLabels = dataLabels\n",
    "        e.dataValues = dataValues\n",
    "        e.clfName = ''\n",
    "\n",
    "        for i in range(numberOfTimes):\n",
    "            start = timer()\n",
    "            #accuracy per step\n",
    "            accuracies, CoreX, CoreY = e.method.start(dataValues=e.dataValues, dataLabels=e.dataLabels, clfName=e.clfName, usePCA=e.usePCA, classes=classes, classifier=e.classifier, densityFunction=e.densityFunction, batches=e.batches, sizeOfBatch = e.sizeOfBatch, initialLabeledDataPerc=e.initialLabeledDataPerc, excludingPercentage=e.excludingPercentage, K=e.K, CP=e.CP, alpha=e.alpha, useSVM=e.useSVM, isImbalanced=e.isImbalanced)\n",
    "            end = timer()\n",
    "            averageAccuracy = np.mean(accuracies)\n",
    "\n",
    "            #elapsed time per step\n",
    "            elapsedTime.append(end - start)\n",
    "\n",
    "            accTotal.append(averageAccuracy)\n",
    "        #print(\"Total of \", numberOfTimes, \" experiment iterations with an average accuracy of \", np.mean(accTotal))\n",
    "        print(\"{} batches of {} instances\".format(e.batches, e.sizeOfBatch))\n",
    "        print(\"Average execution time: \", np.mean(elapsedTime))\n",
    "        #print data distribution in step t\n",
    "        initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "        final = initial + sizeOfBatch\n",
    "        plotFunctions.plot(dataValues[initial:final], dataLabels[initial:final], CoreX, CoreY, batches)\n",
    "        #print(\"\\n\\n\")\n",
    "        metrics.finalEvaluation(accuracies, batches)\n",
    "    \n",
    "    '''\n",
    "    classes = list(set(dataLabels))\n",
    "    initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "    final = initial + sizeOfBatch\n",
    "    plotFunctions.plot2(dataValues[initial:final], dataLabels[initial:final], batches, classes)'''\n",
    "            \n",
    "        \n",
    "def main():\n",
    "    experiments = {}\n",
    "    is_windows = sys.platform.startswith('win')\n",
    "    sep = '\\\\'\n",
    "    \n",
    "    if is_windows == False:\n",
    "        sep = '/'\n",
    "\n",
    "    path = os.getcwd()+sep+'experiments'+sep+'data'+sep\n",
    "    \n",
    "    #loading a dataset\n",
    "    #dataValues, dataLabels = setup.loadKeystroke(path, sep)\n",
    "    #dataValues, dataLabels = setup.loadCheckerBoard(path, 100, 2000)\n",
    "    #dataValues, dataLabels = setup.loadCSurr(path, sep)\n",
    "    dataValues, dataLabels, clfName = setup.loadCDT(path, sep)\n",
    "    \n",
    "    '''\n",
    "    Paper: Core  Support  Extraction  for  Learning  from  Initially  Labeled Nonstationary  Environments  using  COMPOSE\n",
    "    link: http://s3.amazonaws.com/academia.edu.documents/45784667/2014_-_Core_Support_Extraction_for_Learning_from_Initially_Labeled_NSE_using_COMPOSE_-_IJCNN.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1489296600&Signature=9Z5DQZeDxcCtHUw7445uELSkgBg%3D&response-content-disposition=inline%3B%20filename%3DCore_support_extraction_for_learning_fro.pdf\n",
    "    '''\n",
    "    #experiments[0] = Experiment(compose2)\n",
    "    \n",
    "    '''\n",
    "    Original compose (alpha-shape version)\n",
    "    '''\n",
    "    #experiments[1] = Experiment(compose)\n",
    "    \n",
    "    '''\n",
    "    K-Means / SVM\n",
    "    '''\n",
    "    #experiments[2] = Experiment(kmeans_svm)\n",
    "    \n",
    "    ''' Proposed Method 1 (GMM core extraction + Cluster and label) '''\n",
    "    experiments[3] = Experiment(proposed_gmm_core_extraction)\n",
    "    \n",
    "    ''' Proposed Method 2 (GMM core extraction + Random Forest) '''\n",
    "    #experiments[4] = Experiment(compose3)\n",
    "    ''' Proposed Method 9 (GMM core extraction + SVM) '''\n",
    "    #experiments[5] = Experiment(gmm_test)\n",
    "\n",
    "    '''\n",
    "    Proposed method 3 (Intersection between two distributions)\n",
    "    '''\n",
    "    ##experiments[5] = Experiment(intersection, dataValues, dataLabels, \"STARTING TEST Cluster and label as classifier and Intersection between two distributions\")\n",
    "    \n",
    "    '''\n",
    "    Proposed method 4 (Intersection between two distributions + GMM)\n",
    "    '''\n",
    "    #experiments[6] = Experiment(improved_intersection)\n",
    "    \n",
    "    #doExperiments(experiments, 1)\n",
    "    \n",
    "    #running pywidget\n",
    "    def run(sizeOfBatch):\n",
    "        doExperiments(dataValues, dataLabels, experiments, 1, sizeOfBatch)\n",
    "        \n",
    "    v = interact(run, sizeOfBatch=(1, 80, 1));\n",
    "    display(v)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "57a09062147d4a93955a0b60b47086a6": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
