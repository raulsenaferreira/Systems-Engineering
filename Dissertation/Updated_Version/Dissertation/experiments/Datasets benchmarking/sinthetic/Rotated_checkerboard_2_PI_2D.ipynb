{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five Classes Vertical Translation. Bidimensional.\n",
      "100 batches of 240 instances\n",
      "\n",
      "\n",
      "\n",
      "METHOD: Cluster and label as classifier and GMM with BIC and Mahalanobis as core support extraction\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b5b8db68e35a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-b5b8db68e35a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m#params: X, y, method, num of experiment repetitions, num of batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mdoExperiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b5b8db68e35a>\u001b[0m in \u001b[0;36mdoExperiments\u001b[1;34m(dataValues, dataLabels, datasetDescription, experiments, numberOfTimes, batches)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;31m#accuracy per step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0malgorithmName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCoreX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCoreY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataLabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musePCA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musePCA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensityFunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensityFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizeOfBatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizeOfBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialLabeledDataPerc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialLabeledDataPerc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcludingPercentage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcludingPercentage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_variation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK_variation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclfName\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0museSVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0museSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misImbalanced\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misImbalanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0maverageAccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\raul\\Desktop\\GITHUB\\Systems-Engineering\\Dissertation\\methods\\compose_gmm_version.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# ***** Box 5 *****\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mpredictedByClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslicingClusteredData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mselectedIndexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmahalanobisCoreSupportExtraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictedByClass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestModelSelectedByClass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcludingPercentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mselectedIndexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselectedIndexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselectedIndexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\raul\\Desktop\\GITHUB\\Systems-Engineering\\Dissertation\\source\\util.py\u001b[0m in \u001b[0;36mmahalanobisCoreSupportExtraction\u001b[1;34m(Ut, indexesPredictedByClass, bestModelSelectedByClass, excludingPercentage)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mprecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestModelSelectedByClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecisions_\u001b[0m \u001b[1;31m#inverse of covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestModelSelectedByClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mpointIndexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexesPredictedByClass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(os.getcwd()).resolve().parents[2])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from source import plotFunctions\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import setup\n",
    "from source import metrics\n",
    "from methods import static_labelpropagation\n",
    "from methods import sliding_knn\n",
    "from methods import sliding_random_forest\n",
    "from methods import proposed_gmm_decision_boundaries\n",
    "from methods import proposed_gmm_core_extraction\n",
    "from methods import improved_intersection\n",
    "from methods import compose\n",
    "from methods import compose_gmm_version\n",
    "from methods import fast_compose\n",
    "from methods import intersection\n",
    "from methods import testing\n",
    "\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "     def __init__(self, method, K=None, excludingPercentage=None, densityFunction=None, poolSize=None, isBatchMode=None):\n",
    "        #commom for all experiments\n",
    "        self.method = method\n",
    "        #self.initialLabeledDataPerc=0.05 #150 instances for keystroke database and 0.05 % for artificial databases\n",
    "        self.isBatchMode = isBatchMode\n",
    "        self.poolSize = poolSize\n",
    "        self.usePCA=False\n",
    "        #used only by gmm / kde process\n",
    "        self.densityFunction=densityFunction\n",
    "        self.excludingPercentage = excludingPercentage\n",
    "        self.K_variation = K\n",
    "        self.classifier='cluster_and_label'\n",
    "        #used in alpha-shape version only\n",
    "        self.CP=0.65\n",
    "        self.alpha=0.5\n",
    "        #used in kmeans_svm and compose only\n",
    "        self.useSVM=False\n",
    "        self.isImbalanced=False\n",
    "\n",
    "\n",
    "def doExperiments(dataValues, dataLabels, datasetDescription, arrAccSCARGC, finalAccSCARGC, predictedSCARGC, experiments, batches, labeledData):\n",
    "    listOfAccuracies = []\n",
    "    listOfMethods = []\n",
    "    listOfMCCs = []\n",
    "    listOfF1s = []\n",
    "    listOfTimeExecutions = []\n",
    "    sizeOfBatch = int((len(dataLabels)-labeledData)/batches)\n",
    "    \n",
    "    print(datasetDescription)\n",
    "    print(\"{} batches of {} instances\".format(batches, sizeOfBatch))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    for name, e in experiments.items():\n",
    "        CoreX = []\n",
    "        CoreY = []\n",
    "        accTotal = []\n",
    "        accuracies=[]\n",
    "        classes = list(set(dataLabels))#getting all possible classes existent in data\n",
    "        e.sizeOfBatch = sizeOfBatch\n",
    "        e.batches = batches\n",
    "        e.dataLabels = dataLabels\n",
    "        e.dataValues = dataValues\n",
    "        e.clfName = 'lp' #rf = random forests, cl = cluster and label, knn = k-nn, svm = svm\n",
    "\n",
    "        start = timer()\n",
    "        #accuracy per step\n",
    "        algorithmName, accuracies, CoreX, CoreY, arrX, arrY, arrUt, arrYt, arrClf, arrPredicted = e.method.start(dataValues=e.dataValues, dataLabels=e.dataLabels, usePCA=e.usePCA, classes=classes, classifier=e.classifier, densityFunction=e.densityFunction, batches=e.batches, sizeOfBatch = e.sizeOfBatch, initialLabeledData=labeledData, excludingPercentage=e.excludingPercentage, K_variation=e.K_variation, CP=e.CP, alpha=e.alpha, clfName=e.clfName , useSVM=e.useSVM, isImbalanced=e.isImbalanced, poolSize=e.poolSize, isBatchMode=e.isBatchMode)\n",
    "        end = timer()\n",
    "        averageAccuracy = np.mean(accuracies)\n",
    "\n",
    "        #elapsed time per step\n",
    "        elapsedTime = end - start\n",
    "\n",
    "        accTotal.append(averageAccuracy)\n",
    "        \n",
    "        #arrMCC = metrics.mcc(arrYt, arrPredicted)\n",
    "        arrF1 = metrics.F1(arrYt, arrPredicted, 'micro')\n",
    "        listOfAccuracies.append(accuracies)\n",
    "        listOfMethods.append(algorithmName)\n",
    "        #listOfMCCs.append(arrMCC)\n",
    "        listOfF1s.append(arrF1)\n",
    "        listOfTimeExecutions.append(elapsedTime)\n",
    "        \n",
    "        print(\"Execution time: \", elapsedTime)\n",
    "        #print(\"Average MCC: \", np.mean(arrMCC))\n",
    "        print(\"Average F1: \", np.mean(arrF1))\n",
    "        plotFunctions.finalEvaluation(accuracies, batches, algorithmName)\n",
    "        \n",
    "        #print data distribution in step t\n",
    "        initial = (batches*sizeOfBatch)-sizeOfBatch\n",
    "        final = initial + sizeOfBatch\n",
    "        #plotFunctions.plot(dataValues[initial:final], dataLabels[initial:final], CoreX, CoreY, batches)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    # begin SCARGC plots\n",
    "    print(\"Method: SCARGC\")\n",
    "    predictionsSCARGC = labelSCARGC(predictedSCARGC, arrYt)\n",
    "    arrPredictionsSCARGC = [ predictionsSCARGC[i::batches] for i in range(batches) ]\n",
    "    \n",
    "    #arrMCCSCARGC = metrics.mcc(arrYt, arrPredictionsSCARGC)\n",
    "    arrF1SCARGC = metrics.F1(arrYt, arrPredictionsSCARGC, 'macro')\n",
    "    #print(\"Average MCC: \", np.mean(arrMCCSCARGC))\n",
    "    print(\"Average F1: \", np.mean(arrF1SCARGC))\n",
    "    plotFunctions.finalEvaluation(arrAccSCARGC, batches, 'SCARGC')\n",
    "    \n",
    "    listOfMethods.append(\"SCARGC\")\n",
    "    listOfAccuracies.append(arrAccSCARGC)\n",
    "    #listOfMCCs.append(arrMCCSCARGC)\n",
    "    listOfF1s.append(arrF1SCARGC)\n",
    "    # end SCARGC plots\n",
    "    \n",
    "    plotFunctions.plotBoxplot('acc', listOfAccuracies, listOfMethods)\n",
    "    #plotFunctions.plotBoxplot('mcc', listOfMCCs, listOfMethods)\n",
    "    plotFunctions.plotBoxplot('f1', listOfF1s, listOfMethods)\n",
    "    plotFunctions.plotAccuracyCurves(listOfAccuracies, listOfMethods)\n",
    "    plotFunctions.plotBars(listOfTimeExecutions, listOfMethods)\n",
    "    \n",
    "        \n",
    "def accSCARGC(path, sep, key, steps):\n",
    "    resultsSCARGC_1, resultsSCARGC_2 = setup.loadSCARGCBoxplotResults(path, sep)\n",
    "    results = resultsSCARGC_1[key]\n",
    "    res = [ results[i::steps] for i in range(steps) ]\n",
    "    \n",
    "    arrAcc = []\n",
    "    for i in range(steps):\n",
    "        arrAcc.append(sum(res[i])/len(res[i])*100)\n",
    "        #print(len(res[i]))\n",
    "    finalAcc = sum(arrAcc)/steps\n",
    "    \n",
    "    return arrAcc, finalAcc, results\n",
    "\n",
    "\n",
    "#only for binary classification\n",
    "def labelSCARGC(resultsSCARGC, true_labels):\n",
    "    predictions = []\n",
    "    true_labels = np.array(true_labels)\n",
    "    true_labels = true_labels.flatten()\n",
    "    #print(true_labels)\n",
    "    for i in range(len(true_labels)):\n",
    "        if resultsSCARGC[i] == 1:\n",
    "            predictions.append(true_labels[i])\n",
    "        else:\n",
    "            if true_labels[i] == 0:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def main():\n",
    "    experiments = {}\n",
    "    is_windows = sys.platform.startswith('win')\n",
    "    sep = '\\\\'\n",
    "\n",
    "    if is_windows == False:\n",
    "        sep = '/'\n",
    "\n",
    "    path = os.getcwd()+sep+'data'+sep\n",
    "    \n",
    "    steps = 100\n",
    "    labeledData = 50\n",
    "    poolSize = 181\n",
    "    isBatchMode = True\n",
    "    \n",
    "    #sinthetic\n",
    "    dataValues, dataLabels, description = setup.loadCheckerBoard(path, sep)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Paper: Core  Support  Extraction  for  Learning  from  Initially  Labeled Nonstationary  Environments  using  COMPOSE\n",
    "    link: http://s3.amazonaws.com/academia.edu.documents/45784667/2014_-_Core_Support_Extraction_for_Learning_from_Initially_Labeled_NSE_using_COMPOSE_-_IJCNN.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1489296600&Signature=9Z5DQZeDxcCtHUw7445uELSkgBg%3D&response-content-disposition=inline%3B%20filename%3DCore_support_extraction_for_learning_fro.pdf\n",
    "    '''\n",
    "    #experiments[0] = Experiment(compose_gmm_version)\n",
    "\n",
    "    '''\n",
    "    Original compose (alpha-shape version)\n",
    "    '''\n",
    "    #experiments[1] = Experiment(compose)\n",
    "\n",
    "    '''\n",
    "    SVM / Random Forest\n",
    "    '''\n",
    "    #experiments[2] = Experiment(static_svm)\n",
    "    experiments[3] = Experiment(static_labelpropagation, 2)\n",
    "\n",
    "    ''' Proposed Method 1 (GMM core extraction) '''\n",
    "    experiments[4] = Experiment(proposed_gmm_core_extraction, 2, 0.9, \"kde\", poolSize, isBatchMode)\n",
    "\n",
    "    '''\n",
    "    Proposed method 2 (Intersection between two distributions + GMM)\n",
    "    '''\n",
    "    #experiments[5] = Experiment(intersection)\n",
    "    \n",
    "    '''Proposed method 4 (classifying and removing boundaries points with SVM)'''\n",
    "    experiments[7] = Experiment(proposed_gmm_decision_boundaries, 7, None, \"kde\", poolSize, isBatchMode)\n",
    "    experiments[99] = Experiment(improved_intersection, 7, None, \"kde\", poolSize, isBatchMode)\n",
    "    \n",
    "    '''\n",
    "    Proposed method 4 (GMM All instances)\n",
    "    '''\n",
    "    #experiments[6] = Experiment(testing)\n",
    "\n",
    "\n",
    "    doExperiments(dataValues, dataLabels, description, arrAccSCARGC, finalAccSCARGC, predictedSCARGC, experiments, steps, labeledData)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
